= OpenShift Pipelines and Minio

== Event Listeners[[ocppipelines]]

. Login to your OpenShift console.

+
image::openshift/openshift-login-page.png[OpenShift login screen,80%,80%]

. Select *rhsso*. 

+
image::openshift/openshift-rhsso-page.png[OpenShift rhsso screen,80%,80%]

. Login with your username and password.

+
image::openshift/openshift-userpass-page.png[OpenShift user/pass screen,80%,80%]

. You should see the OpenShift Web console with the *summit_project* 

+
image::openshift/ocp-project.png[OpenShift project,100%,100%]

. Scroll down and expand the *Pipelines* section on the left menu. Select the *Triggers*. Note that we have an event listener named *simple-pipeline-listener* setup.

+
image::openshift/ocp-main-triggers.png[OpenShift triggers,100%,100%]

. Click on *Trigger Templates* -> *simple-template* -> *YAML*. The event listener is configured to run this trigger template when activated. This template runs our *start-dsp-pipeline*. 

+
image::openshift/ocp-trigger-template.png[OpenShift trigger template,100%,100%]

. Click on *Pipelines*. You should see the *start-dsp-pipeline*. This OpenShift pipeline is responsible for starting our OpenShift AI Data Science Pipeline.

+
image::openshift/ocp-pipeline.png[OpenShift pipeline,100%,100%]

== Minio[[minio]]

We're using Mino for our s3 buckets.

. Get the route for Mino by going to the OpenShift web console and make sure you change your Project to *All Projects*. Select *Networking* -> *Routes*. Type _minio-ui_ into the search bar and click the *Location* URL to open the Minio web console.

+
image::openshift/minio-route.png[Mino route,100%,100%]

. Login to the Mino web console with the user *minio* and password *minio123*.

+
image::openshift/minio-login.png[Mino login page,80%,80%]

. We'll create an event destination so that our event listener can trigger our OpenShift pipeline whenever we upload files to the s3 bucket.

+
Click on *Events* on the left menu and click on the *Add event destination* button.

+
image::openshift/minio-add-event-destination.png[Mino add event destination,100%,100%]

. Scroll down until you see the webhook function. Click on *Webhook*. 

+
image::openshift/minio-webhook-event.png[Mino webhook event,100%,100%]

. We'll need to get our OpenShift token before we can completely configure the event destination in Minio. 

+
image::openshift/ocp-token.png[OpenShift token,100%,100%]

. Enter in _dsp-event-listener_ for the *Identifier*, the event listener route URL for the *Endpoint*, and your OpenShift token in the *Auth Token* field.

+
Click *Save Event Destination* 

+
image::openshift/minio-event-destination.png[Mino configure event destination,100%,100%]

. Under Administration on the left hand menu click *Buckets*. Open the *upload-files* bucket and click *Events* for the upload-files bucket. Click on *Subscribe to Event*.

+
image::openshift/minio-subscribe-to-events.png[Mino subscribe to events,100%,100%]

. Select the *dsp-event-listener* webhook from the dropdown. Select the *PUT - Object Uploaded* event and click *Save*.

+
image::openshift/minio-subscribe-to-bucket-events.png[Mino subscribe to events,100%,100%]

Your s3 bucket is now configured to send an event to your OpenShift event listener every time a file is uploaded. In the next section we'll upload a file and see how it runs our pipelines!